{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4507366,"sourceType":"datasetVersion","datasetId":2634341}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nimport numpy as np\nimport cv2\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-13T14:01:34.541761Z","iopub.execute_input":"2024-01-13T14:01:34.542236Z","iopub.status.idle":"2024-01-13T14:01:34.549048Z","shell.execute_reply.started":"2024-01-13T14:01:34.542199Z","shell.execute_reply":"2024-01-13T14:01:34.547933Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def read_data(data_path):\n    dataset = []\n    labels = []\n    DIRPATH = os.listdir(data_path)\n    for i in range(len(DIRPATH)):\n        for img in os.listdir(os.path.join(data_path, DIRPATH[i])):\n            image = np.mean(cv2.imread(os.path.join(data_path, DIRPATH[i], img))) // 255\n            # Resize the image to a consistent shape\n            image = cv2.resize(image, (255, 255))\n            dataset.append(image)\n            labels.append(i)\n    return np.array(dataset, dtype=np.float32), np.array(labels, dtype=np.int64)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:01:34.551359Z","iopub.execute_input":"2024-01-13T14:01:34.551761Z","iopub.status.idle":"2024-01-13T14:01:34.565680Z","shell.execute_reply.started":"2024-01-13T14:01:34.551727Z","shell.execute_reply":"2024-01-13T14:01:34.563815Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"training_datapath = '/kaggle/input/bone-fracture-detection-using-xrays/archive (6)/train'\ntraining_data, training_label = read_data(training_datapath)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:01:34.568466Z","iopub.execute_input":"2024-01-13T14:01:34.569453Z","iopub.status.idle":"2024-01-13T14:02:51.384631Z","shell.execute_reply.started":"2024-01-13T14:01:34.569395Z","shell.execute_reply":"2024-01-13T14:02:51.383625Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"testing_datapath = '/kaggle/input/bone-fracture-detection-using-xrays/archive (6)/val'\ntesting_data, testing_label = read_data(testing_datapath)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:02:51.386286Z","iopub.execute_input":"2024-01-13T14:02:51.386657Z","iopub.status.idle":"2024-01-13T14:02:55.872489Z","shell.execute_reply.started":"2024-01-13T14:02:51.386624Z","shell.execute_reply":"2024-01-13T14:02:55.871237Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"len(training_data), len(training_data)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:02:55.875674Z","iopub.execute_input":"2024-01-13T14:02:55.876079Z","iopub.status.idle":"2024-01-13T14:02:55.885482Z","shell.execute_reply.started":"2024-01-13T14:02:55.876044Z","shell.execute_reply":"2024-01-13T14:02:55.884355Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(8863, 8863)"},"metadata":{}}]},{"cell_type":"code","source":"train_data, train_label = shuffle(training_data, training_label)\nprint(train_data.shape)\n\ntest_data, test_label = shuffle(testing_data, testing_label)\nprint(test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:02:55.887125Z","iopub.execute_input":"2024-01-13T14:02:55.887592Z","iopub.status.idle":"2024-01-13T14:02:56.665173Z","shell.execute_reply.started":"2024-01-13T14:02:55.887546Z","shell.execute_reply":"2024-01-13T14:02:56.663652Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(8863, 255, 255)\n(600, 255, 255)\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(255, 255, 1)))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:03:28.832994Z","iopub.execute_input":"2024-01-13T14:03:28.833432Z","iopub.status.idle":"2024-01-13T14:03:28.968181Z","shell.execute_reply.started":"2024-01-13T14:03:28.833399Z","shell.execute_reply":"2024-01-13T14:03:28.966650Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:03:29.480026Z","iopub.execute_input":"2024-01-13T14:03:29.480479Z","iopub.status.idle":"2024-01-13T14:03:29.496371Z","shell.execute_reply.started":"2024-01-13T14:03:29.480439Z","shell.execute_reply":"2024-01-13T14:03:29.495225Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:03:32.024694Z","iopub.execute_input":"2024-01-13T14:03:32.025944Z","iopub.status.idle":"2024-01-13T14:03:32.063377Z","shell.execute_reply.started":"2024-01-13T14:03:32.025883Z","shell.execute_reply":"2024-01-13T14:03:32.061984Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_2 (Conv2D)           (None, 253, 253, 32)      320       \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 126, 126, 32)      0         \n g2D)                                                            \n                                                                 \n conv2d_3 (Conv2D)           (None, 124, 124, 32)      9248      \n                                                                 \n max_pooling2d_3 (MaxPoolin  (None, 62, 62, 32)        0         \n g2D)                                                            \n                                                                 \n flatten_1 (Flatten)         (None, 123008)            0         \n                                                                 \n dense_2 (Dense)             (None, 64)                7872576   \n                                                                 \n dense_3 (Dense)             (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 7882794 (30.07 MB)\nTrainable params: 7882794 (30.07 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(train_data, train_label, epochs=10, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:03:32.559100Z","iopub.execute_input":"2024-01-13T14:03:32.559547Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n139/139 [==============================] - 339s 2s/step - loss: 2.1960 - accuracy: 0.4943\nEpoch 2/10\n139/139 [==============================] - 354s 3s/step - loss: 1.9937 - accuracy: 0.4945\nEpoch 3/10\n139/139 [==============================] - 345s 2s/step - loss: 1.8122 - accuracy: 0.4945\nEpoch 4/10\n139/139 [==============================] - 361s 3s/step - loss: 1.6521 - accuracy: 0.4983\nEpoch 5/10\n139/139 [==============================] - 328s 2s/step - loss: 1.5133 - accuracy: 0.4973\nEpoch 6/10\n139/139 [==============================] - 355s 3s/step - loss: 1.3944 - accuracy: 0.4967\nEpoch 7/10\n139/139 [==============================] - 326s 2s/step - loss: 1.2937 - accuracy: 0.5039\nEpoch 8/10\n139/139 [==============================] - 358s 3s/step - loss: 1.2088 - accuracy: 0.5055\nEpoch 9/10\n 98/139 [====================>.........] - ETA: 1:37 - loss: 1.1470 - accuracy: 0.4970","output_type":"stream"}]},{"cell_type":"code","source":"model.save('fracture_detection.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}